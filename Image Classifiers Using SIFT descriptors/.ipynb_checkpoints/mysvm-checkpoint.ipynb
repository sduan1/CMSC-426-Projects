{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imregionalmax(image, footprint):\n",
    "    \"\"\"Find the regional max of an ND image. An approximation of MATLAB's\n",
    "    imregionalmax function. Result only differs when surrounding pixels\n",
    "    have the same value as the center.\n",
    "\n",
    "    Parameters:\n",
    "    - image: the input image\n",
    "    - footprint: a boolean ndarray specifying which neighboring pixels should be considered\n",
    "                 for thresholding, see scipy.ndimage.generate_binary_structure.\n",
    "    Returns:\n",
    "    - a bitmask image, where '1' indicates local maxima.\n",
    "    Author:\n",
    "    - Yu Fang\n",
    "    References:\n",
    "    - https://github.com/bhardwajvijay/Utils/blob/master/utils.cpp\n",
    "    - https://stackoverflow.com/questions/5550290/find-local-maxima-in-grayscale-image-using-opencv\n",
    "    \"\"\"\n",
    "    # dialate the image so that small values are replaced by local max\n",
    "    local_max = ndimage.grey_dilation(image, footprint=footprint, mode='reflect')\n",
    "    # non-local max pixels (excluding pixel w/ constant 3x3 neighborhood)\n",
    "    # will be replaced by local max, so the values will increase. remove them.\n",
    "    # so the result is either local max or constant neighborhood.\n",
    "    max_mask = image >= local_max\n",
    "    # erode the image so that high values are replaced by local min\n",
    "    local_min = ndimage.grey_erosion(image, footprint=footprint, mode='reflect')\n",
    "    # only local min pixels and pixels w/ constant 3x3 neighborhood\n",
    "    # will stay the same, otherwise pixels will be replaced by the local\n",
    "    # min and become smaller. We only take non-local min, non-constant values.\n",
    "    min_mask = image > local_min\n",
    "    # boolean logic hack\n",
    "    #   (local max || constant) && (!local min && !constant)\n",
    "    # = local max && !local min && !constant\n",
    "    # = local max && !constant\n",
    "    return (max_mask & min_mask).astype(np.uint8)\n",
    "def imregionalmin(image, footprint):\n",
    "    \"\"\"Find the regional min of an ND image. An approximation of MATLAB's\n",
    "    imregionalmin function. Result only differs when surrounding pixels\n",
    "    have the same value as the center.\n",
    "\n",
    "    Parameters:\n",
    "    - image: the input image\n",
    "    - footprint: a boolean ndarray specifying which neighboring pixels should be considered\n",
    "                 for thresholding, see scipy.ndimage.generate_binary_structure.\n",
    "    Returns:\n",
    "    - a bitmask image, where '1' indicates local maxima.\n",
    "    Author:\n",
    "    - Yu Fang\n",
    "    References:\n",
    "    - https://github.com/bhardwajvijay/Utils/blob/master/utils.cpp\n",
    "    - https://stackoverflow.com/questions/5550290/find-local-maxima-in-grayscale-image-using-opencv\n",
    "    \"\"\"\n",
    "    # erode the image so that high values are replaced by local min\n",
    "    local_min = ndimage.grey_erosion(image, footprint=footprint, mode='reflect')\n",
    "    # non-local min pixels (excluding pixel w/ constant 3x3 neighborhood)\n",
    "    # will be replaced by local min, so the values will decrease. remove them.\n",
    "    # so the result is either local min or constant neighborhood.\n",
    "    min_mask = image <= local_min\n",
    "    # dialate the image so that small values are replaced by local max\n",
    "    local_max = ndimage.grey_dilation(image, footprint=footprint, mode='reflect')\n",
    "    # only local max pixels and pixels w/ constant 3x3 neighborhood\n",
    "    # will stay the same, otherwise pixels will be replaced by the local\n",
    "    # max and become larger. We only take non-local max, non-constant values.\n",
    "    max_mask = image < local_max\n",
    "    # boolean logic hack\n",
    "    #   (local min || constant) && (!local max && !constant)\n",
    "    # = local min && !local max && !constant\n",
    "    # = local min && !constant\n",
    "    return (max_mask & min_mask).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localize_kps(imgs, x, y, s):\n",
    "    dx_kernal = np.array([[0,1/2,0],[0,0,0],[0,-1/2,0]])\n",
    "    dy_kernal = np.array([[0,0,0],[1/2,0,-1/2],[0,0,0]])\n",
    "    dxx_kernal = np.array([[0,0,0],[1,-2,1],[0,0,0]])\n",
    "    dyy_kernal = np.array([[0,1,0],[0,-2,0],[0,1,0]])\n",
    "    dxy_kernal = np.array([[-1,0,1],[0,0,0],[1,0,-1]])\n",
    "                          \n",
    "    dx_img = cv2.filter2D(imgs[s], -1, dx_kernal)\n",
    "    dy_img = cv2.filter2D(imgs[s], -1, dy_kernal)\n",
    "    dxx_img = cv2.filter2D(imgs[s], -1, dxx_kernal)\n",
    "    dxy_img = cv2.filter2D(imgs[s], -1, dxy_kernal)\n",
    "    dyy_img = cv2.filter2D(imgs[s], -1, dyy_kernal)\n",
    "    \n",
    "    dx_img_prev = cv2.filter2D(imgs[s-1], -1, dx_kernal)\n",
    "    dx_img_next = cv2.filter2D(imgs[s+1], -1, dx_kernal)\n",
    "    \n",
    "    dy_img_prev = cv2.filter2D(imgs[s-1], -1, dy_kernal)\n",
    "    dy_img_next = cv2.filter2D(imgs[s+1], -1, dy_kernal)\n",
    "    \n",
    "    \n",
    "    dx = dx_img[y, x]\n",
    "    dy = dy_img[y, x]\n",
    "    ds = imgs[s+1][y, x] - imgs[s-1][y,x]\n",
    "    dxx = dxx_img[y, x]\n",
    "    dxy = dxy_img[y, x]\n",
    "    dyy = dyy_img[y, x]\n",
    "    dxs = (dx_img_prev[y, x] - dx_img_next[y, x])/2\n",
    "    dys = (dy_img_prev[y, x] - dy_img_next[y, x])/2\n",
    "    dss = imgs[s+1][y,x] - 2*imgs[s][y,x] + imgs[s-1][y,x]\n",
    "    \n",
    "    J = np.array([dx, dy, ds]) \n",
    "    HD = np.array([ [dxx, dxy, dxs], [dxy, dyy, dys], [dxs, dys, dss]])\n",
    "    \n",
    "    \n",
    "    offset = -np.linalg.pinv(HD).dot(J)\n",
    "    return offset, J, HD[:2,:2], x, y, s\n",
    "\n",
    "def generate_gaussian_kernel(sigma, w):\n",
    "    k = np.zeros((w,w))\n",
    "    x = int(w/2)\n",
    "    k[x][x] = 1.0\n",
    "    g_kernel = cv2.GaussianBlur(k, (w,w), sigma)\n",
    "    return g_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orientation(D, kp, s):\n",
    "    dog_img = D[s]\n",
    "    sigma = 1.5*s\n",
    "    [ky, kx] = kp\n",
    "    w = int(2*np.ceil(sigma)+1)\n",
    "    kernel = generate_gaussian_kernel(s, w)\n",
    "    \n",
    "    dx_kernal = np.array([[0,1/2,0],[0,0,0],[0,-1/2,0]])\n",
    "    dy_kernal = np.array([[0,0,0],[1/2,0,-1/2],[0,0,0]])\n",
    "    dx_img = cv2.filter2D(dog_img, -1, dx_kernal)+1e-15\n",
    "    dy_img = cv2.filter2D(dog_img, -1, dy_kernal)+1e-15\n",
    "    \n",
    "    angle_img = np.degrees(np.arctan(dy_img/dx_img))%360\n",
    "    \n",
    "    try:\n",
    "        y1 = int(ky-w/2)\n",
    "        y2 = int(ky+w/2)\n",
    "        x1 = int(kx-w/2)\n",
    "        x2 = int(kx+w/2)\n",
    "        patch = angle_img[y1:y2, x1:x2]\n",
    "        hist = np.zeros(36, dtype = np.float32)\n",
    "        for y in range(w):\n",
    "            for x in range(w):\n",
    "                hist[int(patch[y,x]//10)] += kernel[y,x] * patch[y,x]\n",
    "\n",
    "    except:\n",
    "        return np.resize(np.array([]),(0,3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    argsorted_hist = np.argsort(hist)\n",
    "    if 0.8*hist[argsorted_hist[-2]]>=hist[argsorted_hist[-1]]:\n",
    "        return np.array([[ky, kx, argsorted_hist[-1]*10],[ky, kx, argsorted_hist[-1]*10]])\n",
    "    else:\n",
    "        return np.array([[ky, kx, argsorted_hist[-1]*10]])\n",
    "    \n",
    "def get_descriptor(new_kp, D_img):\n",
    "    [y, x, theta] = new_kp\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    try:\n",
    "        kp_sub_area = D_img[y-13:y+13,x-13:x+13]\n",
    "        plt.imshow(kp_sub_area,cmap='gray')\n",
    "        M = cv2.getRotationMatrix2D((13,13), theta, 1.0)\n",
    "        rotated_sub_area = cv2.warpAffine(kp_sub_area, M, np.shape(kp_sub_area))\n",
    "\n",
    "        dx_kernal = np.array([[0,1/2,0],[0,0,0],[0,-1/2,0]])\n",
    "        dy_kernal = np.array([[0,0,0],[1/2,0,-1/2],[0,0,0]])\n",
    "        dx_img = cv2.filter2D(rotated_sub_area, -1, dx_kernal)+1e-15\n",
    "        dy_img = cv2.filter2D(rotated_sub_area, -1, dy_kernal)+1e-15\n",
    "\n",
    "        angle_img = np.degrees(np.arctan(dy_img/dx_img))%360\n",
    "\n",
    "        angle_subarea = angle_img[13-8:13+8, 13-8:13+8]\n",
    "        descriptor = np.array(subarea_to_descriptor(angle_subarea))\n",
    "        descriptor = np.ndarray.flatten(descriptor)\n",
    "\n",
    "        return descriptor\n",
    "    except Exception as e:\n",
    "        return np.reshape(np.array([]),(0,128))\n",
    "    \n",
    "    \n",
    "def subarea_to_descriptor(sub_area):\n",
    "    sub_regions = [sub_area[y:y+4, x:x+4] for x in range(0,16,4) for y in range(0,16,4)]\n",
    "    \n",
    "    descriptor = []\n",
    "    for sub_region in sub_regions:\n",
    "        descriptor.append(sub_region_to_hist(sub_region))\n",
    "    return descriptor\n",
    "        \n",
    "        \n",
    "def sub_region_to_hist(sub_region):\n",
    "    kernel = np.array([[1,3,3,1],[3,9,9,3],[3,9,9,3],[1,3,3,1]])/64\n",
    "    hist = np.zeros(8, dtype = np.float32)\n",
    "    for y in range(4):\n",
    "        for x in range(4):\n",
    "            hist[int(sub_region[y,x]//45)] += sub_region[y,x]*kernel[y,x]\n",
    "            \n",
    "    hist /= np.linalg.norm(hist)\n",
    "    hist[hist>0.2] = 0.2\n",
    "    hist /= np.linalg.norm(hist)\n",
    "    \n",
    "    return hist\n",
    "\n",
    "\n",
    "def dof_to_candidate_kps(dof, s):\n",
    "    c_kps = []\n",
    "    (d_h, d_w) = np.shape(dof[s])\n",
    "    mask = np.array([[True, True, True],[True, False, True],[True, True, True]])\n",
    "    for m in range(1, d_h-1):\n",
    "        for n in range(1, d_w-1):\n",
    "            max_val1 = np.max(dof[s][m-1:m+2,n-1:n+2][mask])\n",
    "            max_val2 = np.max(dof[s-1][m-1:m+2,n-1:n+2])\n",
    "            max_val3 = np.max(dof[s+1][m-1:m+2,n-1:n+2])\n",
    "\n",
    "            min_val1 = np.min(dof[s][m-1:m+2,n-1:n+2][mask])\n",
    "            min_val2 = np.min(dof[s-1][m-1:m+2,n-1:n+2])\n",
    "            min_val3 = np.min(dof[s+1][m-1:m+2,n-1:n+2])\n",
    "            if dof[s][m][n] > max(max_val1, max_val2, max_val3) or dof[s][m][n] < min(min_val1, min_val2, min_val3):\n",
    "                c_kps.append([m, n])\n",
    "\n",
    "\n",
    "    c = np.array(c_kps)\n",
    "    return(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dof_to_descriptors(dof):\n",
    "    dof_max1 = imregionalmax(np.stack((dof[0],dof[1],dof[2])), ndimage.generate_binary_structure(3,3))[1]\n",
    "    dof_min1 = imregionalmin(np.stack((dof[0],dof[1],dof[2])), ndimage.generate_binary_structure(3,3))[1]\n",
    "        \n",
    "    dof_max2 = imregionalmax(np.stack((dof[1],dof[2],dof[3])), ndimage.generate_binary_structure(3,3))[1]\n",
    "    dof_min2 = imregionalmin(np.stack((dof[1],dof[2],dof[3])), ndimage.generate_binary_structure(3,3))[1]\n",
    "    \n",
    "    dof_max3 = imregionalmax(np.stack((dof[2],dof[3],dof[4])), ndimage.generate_binary_structure(3,3))[1]\n",
    "    dof_min3 = imregionalmin(np.stack((dof[2],dof[3],dof[4])), ndimage.generate_binary_structure(3,3))[1]\n",
    "    \n",
    "    candidate_kps1 = np.vstack((np.array(np.where(dof_max1)).T, np.array(np.where(dof_min1)).T))\n",
    "\n",
    "    candidate_kps2 = np.vstack((np.array(np.where(dof_max2)).T, np.array(np.where(dof_min2)).T))\n",
    "\n",
    "    candidate_kps3 = np.vstack((np.array(np.where(dof_max3)).T, np.array(np.where(dof_min3)).T))\n",
    "    \n",
    "    filtered_kps1 = []\n",
    "    for kp in candidate_kps1:\n",
    "        [y, x] = kp\n",
    "        offset, J, HD, x, y, s = localize_kps(dof, x, y, 1)\n",
    "        res = dof[1][y,x] + 0.5*np.dot(J.T,offset)\n",
    "        if abs(res) >= 0.03:\n",
    "            w, v = np.linalg.eig(HD)\n",
    "            w += 10e-15\n",
    "            r = w[1]/w[0]\n",
    "            R = (r+1)**2/r\n",
    "            if R >= (10+1)**2/10:\n",
    "\n",
    "                filtered_kps1.append(kp)\n",
    "    filtered_kps1 = np.array(filtered_kps1)\n",
    "    print('len of filtered_kps1:{}'.format(len(filtered_kps1)))\n",
    "    \n",
    "    filtered_kps2 = []\n",
    "\n",
    "    for kp in candidate_kps2:\n",
    "        [y, x] = kp\n",
    "        offset, J, HD, x, y, s = localize_kps(dof, x, y, 2)\n",
    "        res = dof[2][y,x] + 0.5*np.dot(J.T,offset)\n",
    "        if abs(res) >= 0.03:\n",
    "            w, v = np.linalg.eig(HD)\n",
    "            w += 10e-15\n",
    "            r = w[1]/w[0]\n",
    "            R = (r+1)**2/r\n",
    "            if R >= (10+1)**2/10:\n",
    "\n",
    "                filtered_kps2.append(kp)\n",
    "    filtered_kps2 = np.array(filtered_kps2)\n",
    "    print('len of filtered_kps2:{}'.format(len(filtered_kps2)))\n",
    "    \n",
    "    filtered_kps3 = []\n",
    "    for kp in candidate_kps3:\n",
    "        [y, x] = kp\n",
    "        offset, J, HD, x, y, s = localize_kps(dof, x, y, 3)\n",
    "        res = dof[3][y,x] + 0.5*np.dot(J.T,offset)\n",
    "        if abs(res) >= 0.03:\n",
    "            w, v = np.linalg.eig(HD)\n",
    "            w += 10e-15\n",
    "            r = w[1]/w[0]\n",
    "            R = (r+1)**2/r\n",
    "            if R >= (10+1)**2/10:\n",
    "                filtered_kps3.append(kp)\n",
    "    filtered_kps3 = np.array(filtered_kps3)\n",
    "    print('len of filtered_kps3:{}'.format(len(filtered_kps3)))\n",
    " \n",
    "    try:\n",
    "        kps_and_orientation1 = np.vstack(tuple([get_orientation(dof, kp, 1) for kp in filtered_kps1]))\n",
    "        des1 = np.vstack(tuple([get_descriptor(kp, dof[1]) for kp in kps_and_orientation1]))\n",
    "\n",
    "    except:\n",
    "        des1 = np.reshape(np.array([]),(0,128))\n",
    "    \n",
    "    try:\n",
    "        kps_and_orientation2 = np.vstack(tuple([get_orientation(dof, kp, 2) for kp in filtered_kps2]))\n",
    "        des2 = np.vstack(tuple([get_descriptor(kp, dof[2]) for kp in kps_and_orientation2]))\n",
    "\n",
    "    except:\n",
    "        des2 = np.reshape(np.array([]),(0,128))\n",
    "        \n",
    "    try:\n",
    "        kps_and_orientation3 = np.vstack(tuple([get_orientation(dof, kp, 3) for kp in filtered_kps3]))\n",
    "        des3 = np.vstack(tuple([get_descriptor(kp, dof[3]) for kp in kps_and_orientation3]))\n",
    "\n",
    "    except:\n",
    "        des3 = np.reshape(np.array([]),(0,128))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(np.vstack((des1,des2,des3)))\n",
    "    print(np.shape(np.vstack((des1,des2,des3))))\n",
    "    print('finished')\n",
    "    \n",
    "    return(np.vstack((des1,des2,des3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_descriptors(test_img):\n",
    "    \n",
    "    # creating feature space\n",
    "    (oct1_h, oct1_w) = np.shape(test_img)\n",
    "    octave1 = [cv2.GaussianBlur(test_img, (5,5), 2**(i/5)).astype(np.float64) for i in range(6)]\n",
    "    dof1 = [abs(octave1[i+1] - octave1[i])/255 for i in range(5)]\n",
    "\n",
    "    test_img2 = cv2.resize(test_img,((int(np.shape(test_img)[1]/2), int(np.shape(test_img)[0]/2))))\n",
    "    octave2 = [cv2.GaussianBlur(test_img2, (5,5), 2**(i/5)).astype(np.float64) for i in range(6)]\n",
    "    dof2 = [abs(octave2[i+1] - octave2[i])/255 for i in range(5)]\n",
    "\n",
    "    test_img3 = cv2.resize(test_img,((int(np.shape(test_img2)[1]/2), int(np.shape(test_img2)[0]/2))))\n",
    "    octave3 = [cv2.GaussianBlur(test_img3, (5,5), 2**(i/5)).astype(np.float64) for i in range(6)]\n",
    "    dof3 = [abs(octave3[i+1] - octave3[i])/255 for i in range(5)]\n",
    "\n",
    "    test_img4 = cv2.resize(test_img,((int(np.shape(test_img3)[1]/2), int(np.shape(test_img3)[0]/2))))\n",
    "    octave4 = [cv2.GaussianBlur(test_img4, (5,5), 2**(i/5)).astype(np.float64) for i in range(6)]\n",
    "    dof4 = [abs(octave4[i+1] - octave4[i])/255 for i in range(5)]\n",
    "\n",
    "    test_img5 = cv2.resize(test_img,((int(np.shape(test_img4)[1]/2), int(np.shape(test_img4)[0]/2))))\n",
    "    octave5 = [cv2.GaussianBlur(test_img5, (5,5), 2**(i/5)).astype(np.float64) for i in range(6)]\n",
    "    dof5 = [abs(octave5[i+1] - octave5[i])/255 for i in range(5)]\n",
    "    \n",
    "    print('initiating')\n",
    "    \n",
    "    \n",
    "    dof2_descriptors = dof_to_descriptors(dof2)\n",
    "    \n",
    "    \n",
    "    return(dof2_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "def generate_pkl_files(obj, N):\n",
    "    for file_name in listdir(obj)[0:N]:\n",
    "        img_name = file_name.split('.')[0]\n",
    "        \n",
    "        img_path = obj+'/' + img_name+'.jpg'\n",
    "        pkl_path = obj+'_descriptors/'+img_name+'_descriptor.pkl'\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        try:\n",
    "            f = open(pkl_path, 'wb')\n",
    "            pkl.dump(img_to_descriptors(img), f)\n",
    "            f.close()\n",
    "            print('successfully stored: ' + img_name)\n",
    "        except Exception as e:\n",
    "            print('error: ' + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_pkl_files(obj):\n",
    "    for file_name in listdir(obj+'_test'):\n",
    "        img_name = file_name.split('.')[0]\n",
    "        img_path = obj+'_test/'+file_name\n",
    "        pkl_path = obj+'_test_descriptors/'+img_name+'_descriptors.pkl'\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        try:\n",
    "            f = open(pkl_path, 'wb')\n",
    "            pkl.dump(img_to_descriptors(img), f)\n",
    "            f.close()\n",
    "            print('successfully stored: ' + img_name)\n",
    "        except Exception as e:\n",
    "            print('error: ' + str(e))\n",
    "        \n",
    "generate_test_pkl_files('airplanes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_pkl_files('Leopards', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genereate bag of visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27635, 128)\n"
     ]
    }
   ],
   "source": [
    "all_descriptors = []\n",
    "for des_name in listdir('Leopards_descriptors'):\n",
    "    pkl_name = 'Leopards_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    all_descriptors.append(des)\n",
    "    \n",
    "for des_name in listdir('dolphin_descriptors'):\n",
    "    pkl_name = 'dolphin_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    all_descriptors.append(des)\n",
    "    \n",
    "for des_name in listdir('airplanes_descriptors'):\n",
    "    pkl_name = 'airplanes_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    all_descriptors.append(des)\n",
    "all_descriptors = np.vstack(tuple(all_descriptors))\n",
    "print(np.shape(all_descriptors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 50\n",
    "kmeans = KMeans(n_clusters = n_clusters, random_state=0).fit(all_descriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 29, 26, ..., 42, 16, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptors_to_hist(descriptors,k_mean_model):\n",
    "    des = descriptors[0:20]\n",
    "    hist = np.zeros(n_clusters, dtype = np.float32)\n",
    "    for i in k_mean_model.predict(des):\n",
    "        hist[i] += 1\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n",
      "(50, 50)\n"
     ]
    }
   ],
   "source": [
    "leopard_descriptors = []\n",
    "\n",
    "for des_name in listdir('Leopards_descriptors'):\n",
    "    pkl_name = 'Leopards_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    leopard_descriptors.append(des)\n",
    "leopard_hist = np.vstack(tuple([descriptors_to_hist(d, kmeans) for d in leopard_descriptors]))\n",
    "leopard_label = np.ones(50)\n",
    "print(leopard_hist)\n",
    "print(leopard_label)\n",
    "print(np.shape(leopard_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolphin_descriptors = []\n",
    "\n",
    "for des_name in listdir('dolphin_descriptors'):\n",
    "    pkl_name = 'dolphin_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    dolphin_descriptors.append(des)\n",
    "dolphin_hist = np.vstack(tuple([descriptors_to_hist(d, kmeans) for d in dolphin_descriptors]))\n",
    "dolphin_label = np.zeros(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "airplanes_descriptors = []\n",
    "\n",
    "for des_name in listdir('airplanes_descriptors'):\n",
    "    pkl_name = 'airplanes_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    airplanes_descriptors.append(des)\n",
    "airplanes_hist = np.vstack(tuple([descriptors_to_hist(d, kmeans) for d in airplanes_descriptors]))\n",
    "airplanes_label = np.zeros(50)\n",
    "print(len(airplanes_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leopard vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = np.vstack((leopard_hist, dolphin_hist, airplanes_hist)), np.hstack((leopard_label, dolphin_label,np.zeros(50)))\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 50)\n"
     ]
    }
   ],
   "source": [
    "leopard_test_descriptors = []\n",
    "\n",
    "for des_name in listdir('Leopards_test_descriptors'):\n",
    "    pkl_name = 'Leopards_test_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    leopard_test_descriptors.append(des)\n",
    "leopard_test_hist = np.vstack(tuple([descriptors_to_hist(d, kmeans) for d in leopard_test_descriptors]))\n",
    "print(np.shape(leopard_test_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolphin_test_descriptors = []\n",
    "\n",
    "for des_name in listdir('dolphin_test_descriptors'):\n",
    "    pkl_name = 'dolphin_test_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    dolphin_test_descriptors.append(des)\n",
    "dolphin_test_hist = np.vstack(tuple([descriptors_to_hist(d, kmeans) for d in dolphin_test_descriptors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "airplanes_test_descriptors = []\n",
    "\n",
    "for des_name in listdir('airplanes_test_descriptors'):\n",
    "    pkl_name = 'airplanes_test_descriptors/'+des_name\n",
    "    f = open(pkl_name,'rb')\n",
    "    des = pkl.load(f)\n",
    "    f.close()\n",
    "    airplanes_test_descriptors.append(des)\n",
    "airplanes_test_hist = np.vstack(tuple([descriptors_to_hist(d, kmeans) for d in airplanes_test_descriptors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "actual\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "number of mismatch\n",
      "8\n",
      "accuarcy\n",
      "0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "X_test = np.vstack((leopard_test_hist, dolphin_test_hist, airplanes_test_hist))\n",
    "Y_test = np.hstack((np.ones(15),np.zeros(30)))\n",
    "y_pred = clf.predict(X_test)\n",
    "mismatch = len(y_pred[y_pred!=Y_test])\n",
    "acc = (len(y_pred) - mismatch)/len(y_pred)\n",
    "print('prediction')\n",
    "print(y_pred)\n",
    "print('actual')\n",
    "print(Y_test)\n",
    "print('number of mismatch')\n",
    "print(mismatch)\n",
    "print('accuarcy')\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airplanes VS all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = np.vstack((airplanes_hist, leopard_hist, dolphin_hist)), np.hstack((np.ones(50),np.zeros(100)))\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack((airplanes_test_hist, leopard_test_hist, dolphin_test_hist))\n",
    "Y_test = np.hstack((np.ones(15),np.zeros(30)))\n",
    "y_pred = clf.predict(X_test)\n",
    "mismatch = len(y_pred[y_pred!=Y_test])\n",
    "acc = (len(y_pred) - mismatch)/len(y_pred)\n",
    "print('prediction')\n",
    "print(y_pred)\n",
    "print('actual')\n",
    "print(Y_test)\n",
    "print('number of mismatch')\n",
    "print(mismatch)\n",
    "print('accuarcy')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dolphins VS all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = np.vstack((dolphin_hist, leopard_hist, airplanes_hist)), np.hstack((np.ones(50),np.zeros(100)))\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "actual\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "number of mismatch\n",
      "15\n",
      "accuarcy\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "X_test = np.vstack((dolphin_test_hist, leopard_test_hist, airplanes_test_hist))\n",
    "Y_test = np.hstack((np.ones(15),np.zeros(30)))\n",
    "y_pred = clf.predict(X_test)\n",
    "mismatch = len(y_pred[y_pred!=Y_test])\n",
    "acc = (len(y_pred) - mismatch)/len(y_pred)\n",
    "print('prediction')\n",
    "print(y_pred)\n",
    "print('actual')\n",
    "print(Y_test)\n",
    "print('number of mismatch')\n",
    "print(mismatch)\n",
    "print('accuarcy')\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result shown in the previous blocks, we can construct a confusion matrix as shown in the following block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{bmatrix}\n",
    "A/P & Leopard & Airplane & Dolphin\\\\\n",
    "Leopard& 37 & 5 & 3\\\\\n",
    "Airplane & 3 & 38 & 4\\\\\n",
    "Dolphin & 7 & 8 & 30\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A visualization of histogram of bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiating\n",
      "len of filtered_kps1:53\n",
      "len of filtered_kps2:513\n",
      "len of filtered_kps3:63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiyu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Attempting to set identical bottom == top == -0.5 results in singular transformations; automatically expanding.\n",
      "C:\\Users\\shiyu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Attempting to set identical left == right == -0.5 results in singular transformations; automatically expanding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.55182078e-01 4.31319028e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  6.58815145e-01 6.58815145e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  6.51445627e-01 6.51445627e-01]\n",
      " [1.98123039e-13 5.77350259e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  5.04136860e-01 6.10442758e-01]\n",
      " ...\n",
      " [4.96419147e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  6.02562606e-01 6.75026596e-01]\n",
      " [2.80419867e-02 1.20390542e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  7.04833329e-01 7.04833329e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  5.77350259e-01 5.77350259e-01]]\n",
      "(446, 128)\n",
      "finished\n",
      "sample_visbag\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARkAAAD4CAYAAADYf5KEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMLUlEQVR4nO3dX4hc9RnG8edpqhdrAoloQoxptRJKpdBYllCwNFtEid5ELyzmoqQgJBcKCr1o8Cabi4KUantThIjBFPyDoNZcSGsIummhiKsEjU1NgkSNCdlKLjTshahvL/YkrnFn58zMeeecM/l+YJmZM2fnvPvb3YffmXnnN44IAUCW79RdAIDRRsgASEXIAEhFyABIRcgASPXdYR5sbGwsli9fPsxDogfLli2r7LGOHj3adZ+lS5dWdrwqnTt3rtR+VdZf5pgNHq9PIuLqTvcPNWSWL1+u7du3D/OQ6MHExMRQH2t8fLyy41XptddeK7VflfWXOWaDx+uDxe4f6HTJ9ibb79k+bnvHII8FYDT1HTK2l0j6i6TbJd0oaYvtG6sqDMBoGGQms0HS8Yh4PyI+l/SspM3VlAVgVAwSMmskfTTv9sli2zfY3mZ72vb07OzsAIcD0EaDhIwX2PatN0JFxO6IGI+I8bGxsQEOB6CNBgmZk5LWzrt9raRTg5UDYNQMEjJvSFpn+3rbl0u6R9K+asoCMCr67pOJiC9s3y/pH5KWSNoTEe9WVhkqVaYPY+fOnaUea9euXV33qbLnpmzfShll6qqy9qYqO6ZVjMVAzXgR8bKklweuAsDI4r1LAFIRMgBSETIAUhEyAFIRMgBSETIAUhEyAFIRMgBSDXVlPNSnTOfm1NRUZY9VpqN0mF2nTTfsn3GYx2MmAyAVIQMgFSEDIBUhAyAVIQMgFSEDIBUhAyAVIQMgFc14qM2l0GRXVlUNjk3ETAZAKkIGQCpCBkAqQgZAKkIGQCpCBkAqQgZAKkIGQCpCBkAqOn5RG5bf/FpTu3knJye77tPt98NMBkAqQgZAKkIGQCpCBkAqQgZAKkIGQCpCBkAqQgZAKprx0LMqP+ca5ZVtSqxy7Ms043XDTAZAqoFmMrZPSPpM0peSvoiI8SqKAjA6qjhd+mVEfFLB4wAYQZwuAUg1aMiEpFdsv2l720I72N5me9r29Ozs7ICHA9A2g54u3RwRp2yvlLTf9n8j4uD8HSJit6TdknTNNdfEgMcD0DIDzWQi4lRxOSPpRUkbqigKwOjoO2RsX2F72fnrkm6TdLiqwgCMhkFOl1ZJetH2+cd5OiL+XklVAEZG3yETEe9L+kmFtaAlqloOk2U1v1ZmLMo+Vpn9hjn2vIQNIBUhAyAVIQMgFSEDIBUhAyAVIQMgFSEDIBUhAyAVy2/igo0bN5bab2pqKrmSb6pyOclhNwBeCg2H3TCTAZCKkAGQipABkIqQAZCKkAGQipABkIqQAZCKkAGQipABkIqOX1xQZSdvlctJ0jXbm6aNFzMZAKkIGQCpCBkAqQgZAKkIGQCpCBkAqQgZAKkIGQCpaMZDiiqXzGyzso1xTfv86l50q52ZDIBUhAyAVIQMgFSEDIBUhAyAVIQMgFSEDIBUhAyAVIQMgFR0/OKCjRs3ltpv165dXfepcvnNKjW1a7apdVXxO+o6k7G9x/aM7cPztl1pe7/tY8XlioErATCSypwuPSlp00Xbdkg6EBHrJB0obgPAt3QNmYg4KOnsRZs3S9pbXN8r6c6K6wIwIvp94ndVRJyWpOJyZXUlARgl6a8u2d5me9r29OzsbPbhADRMvyFzxvZqSSouZzrtGBG7I2I8IsbHxsb6PByAtuo3ZPZJ2lpc3yrppWrKATBqyryE/Yykf0v6oe2Ttu+V9LCkW20fk3RrcRsAvqVrM15EbOlw1y0V14JLTNkGtCob+6psABx2A11blzTlbQUAUhEyAFIRMgBSETIAUhEyAFIRMgBSETIAUhEyAFIRMgBSsfwm0Kc2dw+XVUW3NTMZAKkIGQCpCBkAqQgZAKkIGQCpCBkAqQgZAKkIGQCpaMbDBVNTU6X2G/bnXDd12ckqG+ia+jMO5bOwAWAQhAyAVIQMgFSEDIBUhAyAVIQMgFSEDIBUhAyAVIQMgFR0/KJnw+5ObWpnbZnHauqymmWx/CaAxiNkAKQiZACkImQApCJkAKQiZACkImQApCJkAKSiGQ8pyjRxTU5OVvZYdRj2MqRlx6FpTYLMZACk6hoytvfYnrF9eN62Sdsf2z5UfN2RWyaAtiozk3lS0qYFtv8pItYXXy9XWxaAUdE1ZCLioKSzQ6gFwAga5DmZ+22/XZxOrei0k+1ttqdtT8/Ozg5wOABt1G/IPCbpBknrJZ2W9EinHSNid0SMR8T42NhYn4cD0FZ9hUxEnImILyPiK0mPS9pQbVkARkVfIWN79bybd0k63GlfAJe2rs14tp+RNCHpKtsnJe2UNGF7vaSQdELS9sQaAbRY15CJiC0LbH4ioRaMkKZ+gHwZdXQYD7t7eJjo+AWQipABkIqQAZCKkAGQipABkIqQAZCKkAGQipABkIrlN4GLlG16a+pndDfteMxkAKQiZACkImQApCJkAKQiZACkImQApCJkAKQiZACkImQApKLjFz2raqnINnfMVn3Mpo5FFb9rZjIAUhEyAFIRMgBSETIAUhEyAFIRMgBSETIAUhEyAFLRjIeeVdXsVccyl1Vqc11lx76K3zUzGQCpCBkAqQgZAKkIGQCpCBkAqQgZAKkIGQCpCBkAqQgZAKno+L1EDHs5zCoNe2nNsuNQx5KfZZSpf5g/Y9eZjO21tl+1fcT2u7YfKLZfaXu/7WPF5YqBqwEwcsqcLn0h6bcR8SNJP5N0n+0bJe2QdCAi1kk6UNwGgG/oGjIRcToi3iqufybpiKQ1kjZL2lvstlfSnVlFAmivnp74tX2dpJskvS5pVUScluaCSNLKDt+zzfa07enZ2dnBqgXQOqVDxvZSSc9LejAiPi37fRGxOyLGI2J8bGysnxoBtFipkLF9meYC5qmIeKHYfMb26uL+1ZJmckoE0GZlXl2ypCckHYmIR+fdtU/S1uL6VkkvVV8egLYr0ydzs6RfS3rH9qFi20OSHpb0nO17JX0o6e6cEgG0WdeQiYh/SXKHu2+pthxkaWqjXRnD/pzoKpcFbepndA/z74G3FQBIRcgASEXIAEhFyABIRcgASEXIAEhFyABIRcgASEXIAEjF8puoTVO7kKusq46lPIddf7famckASEXIAEhFyABIRcgASEXIAEhFyABIRcgASEXIAEjliBjewez/Sfrgos1XSfpkaEVUi9rr0ebapXbXv1Dt34+Iqzt9w1BDZsEC7OmIGK+1iD5Rez3aXLvU7vr7qZ3TJQCpCBkAqZoQMrvrLmAA1F6PNtcutbv+nmuv/TkZAKOtCTMZACOMkAGQqraQsb3J9nu2j9veUVcd/bJ9wvY7tg/Znq67nsXY3mN7xvbheduutL3f9rHickWdNXbSofZJ2x8XY3/I9h111tiJ7bW2X7V9xPa7th8otjd+7Bepveexr+U5GdtLJB2VdKukk5LekLQlIv4z9GL6ZPuEpPGIaHxTle1fSDon6a8R8eNi2x8knY2Ih4uQXxERv6uzzoV0qH1S0rmI+GOdtXVje7Wk1RHxlu1lkt6UdKek36jhY79I7b9Sj2Nf10xmg6TjEfF+RHwu6VlJm2uqZeRFxEFJZy/avFnS3uL6Xs39ATVOh9pbISJOR8RbxfXPJB2RtEYtGPtFau9ZXSGzRtJH826fVJ8/QI1C0iu237S9re5i+rAqIk5Lc39QklbWXE+v7rf9dnE61bjTjYvZvk7STZJeV8vG/qLapR7Hvq6Q8QLb2vZa+s0R8VNJt0u6r5jWYzgek3SDpPWSTkt6pN5yFmd7qaTnJT0YEZ/WXU8vFqi957GvK2ROSlo77/a1kk7VVEtfIuJUcTkj6UXNnQK2yZnivPv8+fdMzfWUFhFnIuLLiPhK0uNq8Njbvkxz/6RPRcQLxeZWjP1Ctfcz9nWFzBuS1tm+3vblku6RtK+mWnpm+4riyTDZvkLSbZIOL/5djbNP0tbi+lZJL9VYS0/O/4MW7lJDx962JT0h6UhEPDrvrsaPfafa+xn72jp+i5e+/ixpiaQ9EfH7Wgrpg+0faG72Is19dtXTTa7f9jOSJjT3Nv0zknZK+puk5yR9T9KHku6OiMY9wdqh9gnNTddD0glJ288/x9Ektn8u6Z+S3pH0VbH5Ic09t9HosV+k9i3qcex5WwGAVHT8AkhFyABIRcgASEXIAEhFyABIRcgASEXIAEj1fxiQhuYq1MXOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img = cv2.imread('airplanes/image_0001.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "sample_des = img_to_descriptors(sample_img)\n",
    "vis_hist = descriptors_to_hist(sample_des, kmeans)\n",
    "print('sample_visbag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying histogram for image 0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('displaying histogram for image 0001')\n",
    "plt.bar(range(50),vis_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
